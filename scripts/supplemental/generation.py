import json
import numpy as np
import pandas as pd
import os, sys
import h5py
import sqlite3
from sqlalchemy import create_engine

sys.path.append(os.path.join(os.getcwd(), "scripts"))
sys.path.append(os.path.join(os.getcwd(), "scripts/trucks"))
sys.path.append(os.getcwd())
# from emme_configuration import *
from EmmeProject import *
import toml

emme_config = toml.load(
    os.path.join(os.getcwd(), "configuration/emme_configuration.toml")
)


def balance_trips(df, trip_purposes, balanced_to):
    """Balance trips to productions or attractions."""
    if balanced_to == "pro":
        to_balance = "att"

    else:
        to_balance = "pro"

    for purposes in trip_purposes:
        total_to_match = sum(df[purposes + balanced_to])
        total_to_balance = sum(df[purposes + to_balance])
        ratio = total_to_match / total_to_balance
        df[purposes + to_balance] = df[purposes + to_balance] * ratio

    return df


def create_df_from_h5(h5_file, h5_table, h5_variables):
    h5_data = {}
    for var in h5_variables:
        h5_data[var] = h5_file[h5_table][var][:]

    return pd.DataFrame(h5_data)


def calc_heavy_truck_restrictions():
    """Restrict truck trips by land use type."""

    #  Load land use type from parcels and a lookup for landuse type codes
    parcels = pd.read_csv(
        r"outputs/landuse/buffered_parcels.txt", sep='\s+'
    )
    df = parcels.merge(
        pd.read_csv(r"inputs/model/lookup/lu_type.csv"),
        left_on="lutype_p",
        right_on="land_use_type_id",
    )

    # The following list of land use types are allowed to be accessed by heavy trucks
    truck_uses = [
        "agriculture",
        "forest",
        "industrial",
        "military",
        "mining",
        "warehousing",
    ]

    truck_df = df[df["land_use_name"].isin(truck_uses)]
    truck_df["taz_p"].value_counts().index.values
    allowed_tazs = truck_df["taz_p"].value_counts().index.values

    return allowed_tazs


def main():
    print(
        "Calculating supplemental trips generated by exterals, special generators, and group quarters."
    )

    # Store these in a config:
    trip_productions = [
        "hbw1pro",
        "hbw2pro",
        "hbw3pro",
        "hbw4pro",
        "colpro",
        "hsppro",
        "hbopro",
        "schpro",
        "otopro",
        "wtopro",
    ]
    trip_attractions = [
        "hbw1att",
        "hbw2att",
        "hbw3att",
        "hbw4att",
        "colatt",
        "hspatt",
        "hboatt",
        "schatt",
        "otoatt",
        "wtoatt",
    ]

    # List of columns that should be balanced to productions or attractions
    balance_to_productions = [
        "hbw1",
        "hbw2",
        "hbw3",
        "hbw4",
        "hsp",
        "hbo",
        "oto",
        "wto",
        "mtk",
        "htk",
        "cvh",
        "dtk",
    ]
    balance_to_attractions = ["col", "sch"]

    # Growth Rates to use for adjsuting input files for specific forecast years
    # Some of these should be calculated and logged in the model directly
    special_generator_rate = 0.0135
    group_quarters_rate = 0.0034
    enlisted_personnel_rate = 0.0000
    jblm_rate = 0.0000
    external_rate = 0.0096
    truck_rate = 0.0135

    # Zone system Inputs
    hightaz = 3700
    lowstation = 3733
    highstation = 3750
    lowpnr = 3751
    highpnr = 4000

    i5_station = 3733

    # Break points for classifications
    # Income in 2014 $'s
    low_income = 37000
    medium_income = 74000
    high_income = 111000

    # Aiport Trip Rates
    air_people = 0.02112
    air_jobs = 0.01486

    # Lists for HH and Person Files
    hh_variables = ["hhno", "hhsize", "hhparcel", "hhincome"]
    person_variables = ["pno", "hhno", "pptyp"]

    employment_categories = [
        "retail",
        "food-services",
        "government",
        "office",
        "services",
        "industrial",
        "education",
        "medical",
        "other",
        "university",
        "total-hh",
        "total-jobs",
        "total-people",
    ]

    # Load parcel file with updated military parcels (processed in create_ixxi_work_trips.py previously)
    parcel_file = "outputs/landuse/parcels_urbansim.txt"

    output_directory = "outputs/supplemental"

    my_project = EmmeProject(emme_config["supplemental_project"])

    conn = create_engine('sqlite:///inputs/db/'+config['db_name'])
    
    ###########################################################
    # PSRC Zone System for TAZ joining
    ###########################################################
    df_psrc = pd.read_sql("SELECT * FROM psrc_zones", con=conn)
    df_psrc["taz"] = df_psrc["taz"].astype(int)
    df_psrc = df_psrc.loc[:, ["taz", "county", "jblm", "external"]]

    ###########################################################
    # Auto External Stations
    ###########################################################

    df_external = pd.read_sql("SELECT * FROM auto_externals where year="+str(config['base_year']), con=conn)
    df_external['taz'] = df_external['taz'].astype(int)
    df_external = df_external.loc[:,['taz','year'] + trip_productions + trip_attractions]
    data_year = int(df_external['year'][0])

    # NOTE: need to scale these measures from a base year

    # Join to full TAZ file to ensure final merging works
    df_external = pd.merge(
        df_psrc, df_external, on="taz", suffixes=("_x", "_y"), how="left"
    )
    df_external.fillna(0, inplace=True)
    df_external.set_index("taz", inplace=True)
    df_external = df_external.loc[:, ["year"] + trip_productions + trip_attractions]
    df_external = df_external.astype(float)

    # Calculate the Inputs for the Year of the model
    if int(config["model_year"]) > data_year:
        growth_rate = 1 + (external_rate * (int(config["model_year"]) - data_year))
        df_external = df_external * growth_rate

    external_taz = df_external.loc[:, trip_productions + trip_attractions]

    ###########################################################
    # Enlisted Personnel
    ###########################################################
    df_enlisted = pd.read_sql_query("SELECT * FROM enlisted_personnel", con=conn)

    ### FIXME: change Zone to taz in DB
    ####
    df_enlisted["taz"] = df_enlisted["Zone"].copy()

    # Select data for model year only
    df_enlisted = df_enlisted[df_enlisted["year"] == int(config["model_year"])][
        ["taz", "military_jobs"]
    ]

    # Aggregate enlisted personnel by TAZ
    enlisted_taz = df_enlisted.groupby("taz").sum().reset_index()
    enlisted_taz["taz"] = enlisted_taz["taz"].astype("int")

    # Read in rates and calculate Enlisted Personnel related trips by Purpose
    df_rates = pd.read_sql_query("SELECT * FROM trip_rates", con=conn)

    df_enlisted_rates = df_rates[df_rates["group"] == "enlisted"]

    for purpose in trip_attractions:
        enlisted_taz[purpose] = (
            enlisted_taz["military_jobs"] * df_enlisted_rates[purpose].values[0]
        )

    # Join to full TAZ file to ensure final merging works
    enlisted_taz = pd.merge(
        df_psrc, enlisted_taz, on="taz", suffixes=("_x", "_y"), how="left"
    )
    enlisted_taz.fillna(0, inplace=True)
    enlisted_taz.set_index("taz", inplace=True)
    enlisted_taz = enlisted_taz.loc[:, trip_attractions]

    ###########################################################
    # Group Quarters
    ###########################################################
    total_gq_df = pd.read_sql_query("SELECT * FROM group_quarters", con=conn)
    total_gq_df[["dorm_share", "military_share", "other_share"]] = total_gq_df[
        ["dorm_share", "military_share", "other_share"]
    ].astype("float")

    # Calculate the Inputs for the Year of the model
    max_input_year = total_gq_df["year"].max()

    if int(config["model_year"]) <= max_input_year:
        total_gq_df = total_gq_df[total_gq_df["year"] == int(config["model_year"])]

    else:
        # Factor group quarters at an annual rate
        total_gq_df = total_gq_df[total_gq_df["year"] == int(max_input_year)]
        total_gq_df["group_quarters"] = total_gq_df["group_quarters"] * (
            1 + (group_quarters_rate * (int(config["model_year"]) - max_input_year))
        )

    total_gq_df = total_gq_df[
        ["taz", "dorm_share", "military_share", "other_share", "group_quarters"]
    ]

    total_gq_df["dorms"] = total_gq_df["group_quarters"] * total_gq_df["dorm_share"]
    total_gq_df["military"] = (
        total_gq_df["group_quarters"] * total_gq_df["military_share"]
    )
    total_gq_df["other"] = total_gq_df["group_quarters"] * total_gq_df["other_share"]

    # Merge with the Block/Taz dataframe and trim down the columns
    total_gq_df = total_gq_df[["taz", "dorms", "military", "other"]]

    # Read in rates and calculate total Group Quarters related trips
    df_gq_rates = df_rates[df_rates["group"] == "group_quarters"]

    for purpose in trip_productions:
        for gq_type in ["dorms", "military", "other"]:
            total_gq_df[purpose] = (
                total_gq_df[gq_type]
                * df_gq_rates[df_gq_rates["segmentation"] == gq_type][purpose].values[0]
            )

    # Consolidate Group Quarters data to TAZ for output to travel model
    group_quarters_taz = total_gq_df.groupby("taz").sum()
    group_quarters_taz = group_quarters_taz.reset_index()
    group_quarters_taz["taz"] = group_quarters_taz["taz"].apply(int)

    # Join to full TAZ file to ensure final merging works
    group_quarters_taz = pd.merge(
        df_psrc, group_quarters_taz, on="taz", suffixes=("_x", "_y"), how="left"
    )
    group_quarters_taz.fillna(0, inplace=True)
    group_quarters_taz.set_index("taz", inplace=True)
    group_quarters_taz = group_quarters_taz[trip_productions]

    ###########################################################
    ### Joint Base Lewis McChord
    ###########################################################
    jblm_df = pd.read_sql_query("SELECT * FROM jblm_trips", con=conn)
    jblm_matrix = int(jblm_df["matrix_id"][0])
    data_year = int(jblm_df["year"][0])

    keep_columns = [
        "origin_zone",
        "destination_zone",
        "trips",
    ]
    jblm_df = jblm_df.loc[:, keep_columns]
    jblm_df["trips"] = jblm_df["trips"].apply(float)

    if int(config["model_year"]) > data_year:
        growth_rate = 1 + (jblm_rate * (int(config["model_year"]) - data_year))
        jblm_df["trips"] = jblm_df["trips"] * growth_rate

    # Create JBLM Input File for use in Emme
    working_file = open(output_directory + "/jblm.in", "w")
    working_file.write("c " + str(config["model_year"]) + " Trip Generation" + "\n")
    working_file.write(
        "c JBLM trips are based on gate counts, blue tooth and zipcode survey data"
        + "\n"
    )
    working_file.write("t matrices" + "\n")
    working_file.write(
        "a matrix=mf" + str(jblm_matrix) + " jblm " + "0 JBLM Trips" + "\n"
    )

    for rows in range(0, (len(jblm_df))):
        origin_zone = jblm_df["origin_zone"][rows]
        destination_zone = jblm_df["destination_zone"][rows]
        working_file.write(
            " "
            + str(origin_zone)
            + " "
            + str(destination_zone)
            + " : "
            + str(jblm_df["trips"][rows])
            + "\n"
        )

    working_file.close()

    ###########################################################
    # Remove JBLM Externals from the Externals dataframe
    ###########################################################

    # Calculate amount of JBLM traffic that is from/to an external and remove it from the External Station df
    jblm_df["origin_zone"] = jblm_df["origin_zone"].apply(int)
    jblm_df["destination_zone"] = jblm_df["destination_zone"].apply(int)

    jblm_external = jblm_df[(jblm_df["origin_zone"] >= lowstation)]
    jblm_ext_productions = sum(jblm_external["trips"])

    jblm_external = jblm_df[(jblm_df["destination_zone"] >= lowstation)]
    jblm_ext_attractions = sum(jblm_external["trips"])

    # Calculate the total trip productions and attractions for the I-5 Zone
    i5_ext_productions = 0
    for purposes in trip_productions:
        i5_ext_productions = i5_ext_productions + external_taz[purposes][i5_station]

    i5_ext_attractions = 0
    for purposes in trip_attractions:
        i5_ext_attractions = i5_ext_attractions + external_taz[purposes][i5_station]

    # Scale the I-5 station volumes by purpose
    i5_revised_productions = i5_ext_productions - jblm_ext_productions
    i5_revised_attractions = i5_ext_attractions - jblm_ext_attractions

    revised_external_taz = external_taz
    for purposes in trip_productions:
        ratio = revised_external_taz[purposes][i5_station] / i5_ext_productions
        revised_external_taz[purposes][i5_station] = i5_revised_productions * ratio

    for purposes in trip_attractions:
        ratio = revised_external_taz[purposes][i5_station] / i5_ext_attractions
        revised_external_taz[purposes][i5_station] = i5_revised_attractions * ratio

    ###########################################################
    # Heavy Truck Productions, grown from ATRI data
    ###########################################################
    heavy_trucks = pd.read_sql_query("SELECT * FROM heavy_trucks", con=conn)
    heavy_trucks = heavy_trucks[["taz", "year", "htkpro", "htkatt"]]

    # Calculate the Inputs for the Year of the model
    data_year = int(heavy_trucks["year"][0])
    heavy_trucks = heavy_trucks.drop("year", axis=1)
    heavy_trucks["htkpro"] = heavy_trucks["htkpro"].apply(float)
    heavy_trucks["htkatt"] = heavy_trucks["htkatt"].apply(float)

    if int(config["model_year"]) > data_year:
        growth_rate = 1 + (truck_rate * (int(config["model_year"]) - data_year))
        heavy_trucks["htkpro"] = heavy_trucks["htkpro"] * growth_rate
        heavy_trucks["htkatt"] = heavy_trucks["htkatt"] * growth_rate

    # Make the TAZ field the index
    heavy_trucks_taz = heavy_trucks.groupby("taz").sum()
    heavy_trucks_taz = heavy_trucks_taz.reset_index()
    heavy_trucks_taz["taz"] = heavy_trucks_taz["taz"].apply(int)

    # Apply land-use restrictions for productions/attraction in TAZs without appropriate industrial uses
    allowed_tazs = calc_heavy_truck_restrictions()
    external_taz_list = list(
        range(emme_config["MIN_EXTERNAL"], emme_config["MAX_EXTERNAL"] + 1)
    )
    allowed_tazs = allowed_tazs.tolist() + external_taz_list

    heavy_trucks_taz = heavy_trucks_taz[heavy_trucks_taz["taz"].isin(allowed_tazs)]

    # Join to full TAZ file to ensure final merging works
    heavy_trucks_taz = pd.merge(
        df_psrc, heavy_trucks_taz, on="taz", suffixes=("_x", "_y"), how="left"
    )
    heavy_trucks_taz.fillna(0, inplace=True)
    heavy_trucks_taz = heavy_trucks_taz.loc[:, ["taz", "htkpro", "htkatt"]]

    ###########################################################
    # SeaTac Airport
    ###########################################################
    df_seatac = pd.read_sql_query("SELECT * FROM seatac", con=conn)
    seatac_zone = df_seatac[df_seatac["year"] == int(config["model_year"])][
        "taz"
    ].values[0]
    seatac_enplanements = df_seatac[df_seatac["year"] == int(config["model_year"])][
        "enplanements"
    ].values[0]

    ###########################################################
    ## Special Generators
    ###########################################################

    # Special generator trips are assumed of type HBO
    df_special = pd.read_sql_query("SELECT * FROM special_generators", con=conn)

    # Calculate the Inputs for the Year of the model
    max_input_year = df_special["year"].max()

    if int(config["model_year"]) <= max_input_year:
        df_special = df_special[df_special["year"] == config["model_year"]]
        df_special["hboatt"] = df_special["trips"].astype("float")

    else:
        df_special = df_special[df_special["year"] == max_input_year]
        df_special["hboatt"] = df_special[df_special["year"] == max_input_year][
            "trips"
        ].astype("float")
        df_special["hboatt"] = df_special["hboatt"] * (
            1 + (special_generator_rate * (int(config["model_year"]) - max_input_year))
        )

    df_special = df_special[["taz", "hboatt"]]

    # Consolidate Special Generator data to TAZ
    special_generators_taz = df_special.groupby("taz").sum()
    special_generators_taz = special_generators_taz.reset_index()
    special_generators_taz["taz"] = special_generators_taz["taz"].apply(int)

    # Join to full TAZ file to ensure final merging works
    special_generators_taz = pd.merge(
        df_psrc, special_generators_taz, on="taz", suffixes=("_x", "_y"), how="left"
    )
    special_generators_taz.fillna(0, inplace=True)
    special_generators_taz.set_index("taz", inplace=True)
    special_generators_taz = special_generators_taz.loc[:, ["hboatt"]]

    ###########################################################
    # Load Household, Person and Parcel files
    ###########################################################

    #### FIXME, fix this
    # Parcel Columns to use and what to rename them
    original_parcel_columns = [
        "parcelid",
        "xcoord_p",
        "ycoord_p",
        "taz_p",
        "empedu_p",
        "empfoo_p",
        "empgov_p",
        "empind_p",
        "empmed_p",
        "empofc_p",
        "empret_p",
        "emprsc_p",
        "empsvc_p",
        "empoth_p",
        "emptot_p",
        "stugrd_p",
        "stuhgh_p",
        "stuuni_p",
    ]
    updated_parcel_columns = [
        "parcel-id",
        "xcoord",
        "ycoord",
        "taz",
        "education",
        "food-services",
        "government",
        "industrial",
        "medical",
        "office",
        "retail",
        "resources",
        "services",
        "other",
        "total-jobs",
        "k-8",
        "high-school",
        "university",
    ]

    hh_person = r"inputs/scenario/landuse/hh_and_persons.h5"
    hh_people = h5py.File(hh_person, "r+")
    hh_df = create_df_from_h5(hh_people, "Household", hh_variables)
    person_df = create_df_from_h5(hh_people, "Person", person_variables)

    parcels = pd.read_csv(parcel_file, sep=" ")
    parcels.columns = parcels.columns.str.lower()
    parcels = parcels.loc[:, original_parcel_columns]
    parcels.columns = updated_parcel_columns

    ###########################################################
    # Create a Household file with cross classifications
    # using the person and household file
    ###########################################################

    person_df["people"] = 1

    # Flag if the person has a full or part-time job
    person_df["workers"] = 0
    person_df.loc[person_df["pptyp"] == 1, "workers"] = 1
    person_df.loc[person_df["pptyp"] == 2, "workers"] = 1

    # Flag if the person is a school age kid
    person_df["school-age"] = 0
    person_df.loc[person_df["pptyp"] == 6, "school-age"] = 1
    person_df.loc[person_df["pptyp"] == 7, "school-age"] = 1

    # Flag if the person is a college student
    person_df["college-student"] = 0
    person_df.loc[person_df["pptyp"] == 5, "college-student"] = 1

    # Remove a couple columns
    fields_to_remove = ["pno", "pptyp"]
    person_df = person_df.drop(fields_to_remove, axis=1)

    # Create a HH file by grouping the person file by household number
    df_hh = person_df.groupby("hhno").sum()
    df_hh = df_hh.reset_index()

    # Merge the HH File created from the persons with the original HH file from H5
    df_hh = pd.merge(df_hh, hh_df, on="hhno", suffixes=("_x", "_y"), how="left")

    # Create a Column for Household sizes 1, 2, 3 or 4+
    df_hh["household-class"] = df_hh["hhsize"]
    df_hh.loc[df_hh["household-class"] > 4, "household-class"] = 4

    # Create a Column for workers 0, 1, 2 or 3+
    df_hh["worker-class"] = df_hh["workers"]
    df_hh.loc[df_hh["worker-class"] > 3, "worker-class"] = 3

    # Create a Column for Income 1, 2 ,3 or 4
    df_hh["income-class"] = 0
    df_hh.loc[df_hh["hhincome"] <= low_income, "income-class"] = 1
    df_hh.loc[
        (df_hh["hhincome"] > low_income) & (df_hh["hhincome"] <= medium_income),
        "income-class",
    ] = 2
    df_hh.loc[
        (df_hh["hhincome"] > medium_income) & (df_hh["hhincome"] <= high_income),
        "income-class",
    ] = 3
    df_hh.loc[df_hh["hhincome"] > high_income, "income-class"] = 4

    # Create a Column for school age children 0, 1, 2 or 3+
    df_hh["school-class"] = df_hh["school-age"]
    df_hh.loc[df_hh["school-class"] > 3, "school-class"] = 3

    # Create a Column for college age persons 0, 1, 2+
    df_hh["college-class"] = df_hh["college-student"]
    df_hh.loc[df_hh["college-class"] > 2, "college-class"] = 2

    # Create a Columns for Household - Work - Income Cross-Classification, Income & School and Income and College
    df_hh["hwi"] = (
        "h"
        + df_hh["household-class"].apply(str)
        + "w"
        + df_hh["worker-class"].apply(str)
        + "i"
        + df_hh["income-class"].apply(str)
    )
    df_hh["si"] = (
        "s" + df_hh["school-class"].apply(str) + "i" + df_hh["income-class"].apply(str)
    )
    df_hh["ci"] = (
        "c" + df_hh["college-class"].apply(str) + "i" + df_hh["income-class"].apply(str)
    )

    ###########################################################
    # Household trip production
    ###########################################################
    df_hh_rates = df_rates[df_rates["group"] == "household"].drop(
        ["schpro", "schatt", "colpro", "colatt"], axis=1
    )
    df_sch_rates = df_rates[df_rates["group"] == "school"][
        ["segmentation", "schpro", "schatt"]
    ]
    df_coll_rates = df_rates[df_rates["group"] == "college"][
        ["segmentation", "colpro", "colatt"]
    ]

    # Merge Rates with Households by Cross-Classification so we end up with total household productions
    df_hh = pd.merge(
        df_hh,
        df_hh_rates,
        left_on="hwi",
        right_on="segmentation",
        suffixes=("_x", "_y"),
        how="left",
    )
    df_hh = pd.merge(
        df_hh,
        df_sch_rates,
        left_on="si",
        right_on="segmentation",
        suffixes=("_x", "_y"),
        how="left",
    )
    df_hh = pd.merge(
        df_hh,
        df_coll_rates,
        left_on="si",
        right_on="segmentation",
        suffixes=("_x", "_y"),
        how="left",
    )
    df_hh = df_hh.loc[:, trip_productions + trip_attractions + ["hhparcel", "people"]]
    df_hh["total-hh"] = 1

    ###########################################################
    # Combine HH Trip Generation with Parcels
    ###########################################################
    df_parcel_hh_pa = df_hh.groupby("hhparcel").sum()
    df_parcel_hh_pa = df_parcel_hh_pa.reset_index()
    df_parcel_hh_pa.rename(
        columns={"hhparcel": "parcel-id", "people": "total-people"}, inplace=True
    )

    ###########################################################
    # Parcel trip attractions
    ###########################################################
    df_parcels = pd.merge(
        parcels, df_parcel_hh_pa, on="parcel-id", suffixes=("_x", "_y"), how="left"
    )
    df_parcels.fillna(0, inplace=True)

    # Create a couple columns for trip attractions for parcels
    df_parcels["education"] = df_parcels["k-8"] + df_parcels["high-school"]
    df_parcels["mtkpro"] = 0
    df_parcels["mtkatt"] = 0
    df_parcels["cvhpro"] = 0
    df_parcels["cvhatt"] = 0
    df_parcels["dtkatt"] = 0
    df_parcels["dtkpro"] = 0

    # Trip Attractions based on employment categories
    df_job_attraction_rates = pd.read_sql_query(
        "SELECT * FROM job_attractions", con=conn
    )
    df_job_attraction_rates.set_index("employment-type", inplace=True)
    attraction_purposes = trip_attractions + ["cvhatt", "mtkatt", "dtkatt"]

    for purpose in attraction_purposes:
        for jobs in employment_categories:
            df_parcels[purpose] = df_parcels[purpose] + (
                df_parcels[jobs] * df_job_attraction_rates.loc[jobs, purpose]
            )

    # Trip Productions based on employment categories
    df_job_production_rates = pd.read_sql_query(
        "SELECT * FROM job_productions", con=conn
    )
    df_job_production_rates.set_index("employment-type", inplace=True)
    productions_purposes = trip_productions + ["cvhpro", "mtkpro", "dtkpro"]

    for purpose in productions_purposes:
        for jobs in employment_categories:
            df_parcels[purpose] = df_parcels[purpose] + (
                df_parcels[jobs] * df_job_production_rates.loc[jobs, purpose]
            )

    # Scale delivery productions based on a target number of delivery trips
    df_parcels["dtkpro"] = emme_config["total_delivery_trips"] * (
        df_parcels["dtkpro"] / df_parcels["dtkpro"].sum()
    )

    ###########################################################
    # SeaTac Airport trip generation
    ###########################################################
    df_parcels["airport"] = (df_parcels["total-jobs"] * air_jobs) + (
        df_parcels["total-people"] * air_people
    )
    aiport_balancing = seatac_enplanements / sum(df_parcels["airport"])
    df_parcels["airport"] = df_parcels["airport"] * aiport_balancing

    ###########################################################
    # Create TAZ Input files
    ###########################################################
    df_taz = df_parcels.groupby("taz").sum()
    df_taz = df_taz.reset_index()
    df_taz.fillna(0, inplace=True)
    df_taz["taz"] = df_taz["taz"].apply(int)

    # Join to full TAZ file to ensure final merging works
    df_taz = pd.merge(df_psrc, df_taz, on="taz", suffixes=("_x", "_y"), how="left")
    df_taz.fillna(0, inplace=True)

    # Create a Kitsap County flag for use in Kitsap Adjustments
    df_taz["kitsap"] = 0
    df_taz.loc[df_taz["county"] == "Kitsap", "kitsap"] = 1

    # Add in Heavy Truck Productions and Attractions
    df_taz = pd.merge(
        df_taz, heavy_trucks_taz, on="taz", suffixes=("_x", "_y"), how="left"
    )
    df_taz.fillna(0, inplace=True)

    # Clean up dataframe for further calculations as well as output
    df_taz.set_index("taz", inplace=True)
    df_taz = df_taz.loc[
        :,
        trip_productions
        + ["cvhpro", "mtkpro", "htkpro", "dtkpro"]
        + trip_attractions
        + ["cvhatt", "mtkatt", "htkatt", "dtkatt", "airport", "kitsap", "jblm"],
    ]
    df_taz.to_csv(output_directory + "/1_unadjusted_unbalanced.csv", index=True)

    # Add in the Group Quarters to Trip Productions
    for purpose in trip_productions:
        df_taz[purpose] = df_taz[purpose] + group_quarters_taz[purpose]
    df_taz.to_csv(output_directory + "/2_add_group_quarters.csv", index=True)

    # Add in the Enlisted Personnel to Trip Attractions
    for purpose in trip_attractions:
        df_taz[purpose] = df_taz[purpose] + enlisted_taz[purpose]
    df_taz.to_csv(output_directory + "/3_add_enlisted_personnel.csv", index=True)

    # Add in the Special Generators to Trip Attractions
    df_taz["hboatt"] = df_taz["hboatt"] + special_generators_taz["hboatt"]
    df_taz.to_csv(output_directory + "/4_add_special_generators.csv", index=True)

    # Add in the External Trips
    all_purposes = trip_productions + trip_attractions
    for purpose in all_purposes:
        df_taz[purpose] = df_taz[purpose] + revised_external_taz[purpose]
    df_taz.to_csv(output_directory + "/5_add_externals.csv", index=True)

    #Soundcast uses pre-determined HSP trips to meet external counts. Need to adjust these here for non-work-ixxi:
    external_trip_table =  pd.read_sql('SELECT * FROM externals_unadjusted where year='+str(config['base_year']), con=conn) 
    external_trip_table.set_index('taz', inplace = True)
    external_trip_table = external_trip_table[['hsppro', 'hspatt']]
    df_taz.update(external_trip_table)

    # Zero out JBLM trips that were generated above (so only inlcude Shopping, HBO, OtO and WtO)
    df_taz["jblm"] = df_taz["jblm"].apply(int)
    jblm_purposes = [
        "hbw1pro",
        "hbw2pro",
        "hbw3pro",
        "hbw4pro",
        "colpro",
        "schpro",
        "cvhpro",
        "mtkpro",
        "htkpro",
        "hbw1att",
        "hbw2att",
        "hbw3att",
        "hbw4att",
        "colatt",
        "schatt",
        "cvhatt",
        "mtkatt",
        "htkatt",
    ]

    for purposes in jblm_purposes:
        df_taz.loc[df_taz["jblm"] == 1, purposes] = 0

    # Adjust the taz level data based on trip rate adjustments
    df_rate_adjustments = pd.read_sql_query("SELECT * FROM rate_adjustments", con=conn)
    df_rate_adjustments.set_index("trip-purpose", inplace=True)
    all_purposes = (
        trip_productions
        + ["cvhpro", "mtkpro", "htkpro"]
        + trip_attractions
        + ["cvhatt", "mtkatt", "htkatt"]
    )

    # Adjust Productions and Attractions by Adjustment Factors
    for purpose in all_purposes:
        df_taz[purpose] = df_taz[purpose] * [
            df_rate_adjustments.loc[purpose, "regional"]
        ]
        df_taz[purpose] = df_taz[purpose] + (
            df_taz[purpose]
            * [df_rate_adjustments.loc[purpose, "kitsap"]]
            * df_taz["kitsap"]
        )

    df_taz.to_csv(output_directory + "/6_adjust_trip_ends.csv", index=True)

    # Balance the taz dataframe
    balanced_df = balance_trips(df_taz, balance_to_productions, "pro")
    balanced_df = balance_trips(df_taz, balance_to_attractions, "att")
    balanced_df.to_csv(output_directory + "/7_balance_trip_ends.csv", index=True)


if __name__ == "__main__":
    main()
